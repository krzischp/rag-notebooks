{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3977cad9-5c46-4836-a58e-6e6ee2c370a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac89ca9-08d4-4f9c-a908-a823f5fcf22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf095f85-1b9a-4430-86bc-28d80bc8037e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:37.902020Z",
     "iopub.status.busy": "2024-05-01T15:44:37.901617Z",
     "iopub.status.idle": "2024-05-01T15:44:37.947058Z",
     "shell.execute_reply": "2024-05-01T15:44:37.946183Z",
     "shell.execute_reply.started": "2024-05-01T15:44:37.901931Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d771622-8d4f-4522-83dd-4ef5eca15c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:38.080327Z",
     "iopub.status.busy": "2024-05-01T15:44:38.079997Z",
     "iopub.status.idle": "2024-05-01T15:44:38.839334Z",
     "shell.execute_reply": "2024-05-01T15:44:38.838663Z",
     "shell.execute_reply.started": "2024-05-01T15:44:38.080299Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a29b0b-d629-44a2-808d-bd85c1ac5060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:38.840854Z",
     "iopub.status.busy": "2024-05-01T15:44:38.840439Z",
     "iopub.status.idle": "2024-05-01T15:44:38.854919Z",
     "shell.execute_reply": "2024-05-01T15:44:38.854218Z",
     "shell.execute_reply.started": "2024-05-01T15:44:38.840834Z"
    }
   },
   "outputs": [],
   "source": [
    "def navigate_up(path, levels):\n",
    "    \"\"\"Navigate up `levels` directories from the given path.\"\"\"\n",
    "    for _ in range(levels):\n",
    "        path = os.path.dirname(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084e8e01-65bc-4d64-a5fc-b3eefdef02e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:38.856242Z",
     "iopub.status.busy": "2024-05-01T15:44:38.856032Z",
     "iopub.status.idle": "2024-05-01T15:44:38.873948Z",
     "shell.execute_reply": "2024-05-01T15:44:38.873361Z",
     "shell.execute_reply.started": "2024-05-01T15:44:38.856222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "llamaindex_dir = os.getcwd()\n",
    "# Get the parent directory\n",
    "llamaindex_dir = os.path.dirname(llamaindex_dir)\n",
    "\n",
    "sys.path.append(llamaindex_dir + \"/utils\")\n",
    "sys.path.append(navigate_up(llamaindex_dir, 2) + \"/law-sec-insights/backend\")\n",
    "# sys.path\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351708be-dd65-47a1-b281-1e4b2be5265f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:38.876399Z",
     "iopub.status.busy": "2024-05-01T15:44:38.875990Z",
     "iopub.status.idle": "2024-05-01T15:44:38.892644Z",
     "shell.execute_reply": "2024-05-01T15:44:38.892013Z",
     "shell.execute_reply.started": "2024-05-01T15:44:38.876369Z"
    }
   },
   "outputs": [],
   "source": [
    "from llamaindex_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e7e0e0c-c473-4149-a6f4-a5dd5ef511ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:38.893751Z",
     "iopub.status.busy": "2024-05-01T15:44:38.893415Z",
     "iopub.status.idle": "2024-05-01T15:44:46.388459Z",
     "shell.execute_reply": "2024-05-01T15:44:46.387710Z",
     "shell.execute_reply.started": "2024-05-01T15:44:38.893727Z"
    }
   },
   "outputs": [],
   "source": [
    "from app.chat.engine import get_chat_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89691402-64a9-4dab-a536-14e864ff417b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:55:16.747838Z",
     "iopub.status.busy": "2024-05-01T15:55:16.747500Z",
     "iopub.status.idle": "2024-05-01T15:55:16.785084Z",
     "shell.execute_reply": "2024-05-01T15:55:16.783899Z",
     "shell.execute_reply.started": "2024-05-01T15:55:16.747811Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b839aa-8e8a-4c6c-95b0-a2d52dd23fa9",
   "metadata": {},
   "source": [
    "# Load data and build an index + Storing your index + Query your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b44d5c4b-5492-4605-b4c3-ea3139558312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:46.416582Z",
     "iopub.status.busy": "2024-05-01T15:44:46.416112Z",
     "iopub.status.idle": "2024-05-01T15:44:46.453264Z",
     "shell.execute_reply": "2024-05-01T15:44:46.452599Z",
     "shell.execute_reply.started": "2024-05-01T15:44:46.416555Z"
    }
   },
   "outputs": [],
   "source": [
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage, get_response_synthesizer\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "# documents = SimpleDirectoryReader(llamaindex_dir + \"/data\").load_data()\n",
    "# index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca88744e-3a87-40d2-9bec-5fd515bd529e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:46.454700Z",
     "iopub.status.busy": "2024-05-01T15:44:46.454423Z",
     "iopub.status.idle": "2024-05-01T15:44:49.777425Z",
     "shell.execute_reply": "2024-05-01T15:44:49.776935Z",
     "shell.execute_reply.started": "2024-05-01T15:44:46.454677Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(llamaindex_dir + \"/data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    # saving the embeddings to disk\n",
    "    # By default, this will save the data to the directory storage, but you can change that by passing a persist_dir parameter.\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94652a-8bd2-45a1-ac10-44d1613a5054",
   "metadata": {},
   "source": [
    "```python\n",
    "# Either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75910b5b-9b1a-49fe-9d1c-00269813f476",
   "metadata": {},
   "source": [
    "How to get lot of data when you have relevant results but potentially no data if you have nothing relevant\n",
    "- we customize our retriever to use a different number for top_k\n",
    "  - For a custom retriever, we use `RetrieverQueryEngine`.\n",
    "- and add a post-processing step that requires that the retrieved nodes reach a minimum similarity score to be included\n",
    "  - For the post-processing step, we use `SimilarityPostprocessor`\n",
    " \n",
    "\n",
    "[Response Synthesizer](https://docs.llamaindex.ai/en/stable/module_guides/querying/response_synthesizers/): A Response Synthesizer is what generates a response from an LLM, using a user query and a given set of text chunks. The output of a response synthesizer is a Response object. When used in a query engine, the response synthesizer is used after nodes are retrieved from a retriever, and after any node-postprocessors are ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ae90b44-678d-4b6f-9e41-ff386a143dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:49.778208Z",
     "iopub.status.busy": "2024-05-01T15:44:49.778072Z",
     "iopub.status.idle": "2024-05-01T15:44:55.686660Z",
     "shell.execute_reply": "2024-05-01T15:44:55.685671Z",
     "shell.execute_reply.started": "2024-05-01T15:44:49.778194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author started writing essays again and even worked on Lisp in March 2015.\n"
     ]
    }
   ],
   "source": [
    "# build index\n",
    "# index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "# query\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd5bf03-eb75-49c7-9343-73f116443844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:44:55.690995Z",
     "iopub.status.busy": "2024-05-01T15:44:55.690698Z",
     "iopub.status.idle": "2024-05-01T15:44:55.730146Z",
     "shell.execute_reply": "2024-05-01T15:44:55.728959Z",
     "shell.execute_reply.started": "2024-05-01T15:44:55.690967Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(RetrieverQueryEngine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a02438-e3a4-4891-9e9c-4047588f1915",
   "metadata": {},
   "source": [
    "# `get_chat_engine`\n",
    "\n",
    "- local implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06324cd-138a-497c-8d83-74c3917588c2",
   "metadata": {},
   "source": [
    "There are a huge variety of retrievers that you can learn about in our [module guide on retrievers](https://docs.llamaindex.ai/en/stable/module_guides/querying/retriever/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5df1fd28-a7c0-4f9d-82ab-a863cb59644d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T19:50:02.683282Z",
     "iopub.status.busy": "2024-05-01T19:50:02.682890Z",
     "iopub.status.idle": "2024-05-01T19:50:02.729641Z",
     "shell.execute_reply": "2024-05-01T19:50:02.728638Z",
     "shell.execute_reply.started": "2024-05-01T19:50:02.683257Z"
    }
   },
   "outputs": [],
   "source": [
    "from app.models.db import MessageRoleEnum, MessageStatusEnum, MessageSubProcess, MessageSubProcessStatusEnum\n",
    "from app.schema import Message, Conversation, Document, DocumentMetadataKeysEnum, SecDocumentTypeEnum\n",
    "from datetime import datetime\n",
    "from uuid import UUID\n",
    "\n",
    "\n",
    "mock_message = Message(\n",
    "    conversation_id=UUID(\"01234567-89ab-cdef-0123-456789abcdef\"),\n",
    "    content=\"Hello, how can I help you?\",\n",
    "    role=MessageRoleEnum.assistant,\n",
    "    status=MessageStatusEnum.SUCCESS,\n",
    "    sub_processes=[\n",
    "        MessageSubProcess(\n",
    "            message_id=UUID(\"01234567-89ab-cdef-0123-456789abcdef\"),\n",
    "            source=\"chunking\",\n",
    "            status=MessageSubProcessStatusEnum.FINISHED,\n",
    "            metadata_map=None\n",
    "        ),\n",
    "        MessageSubProcess(\n",
    "            message_id=UUID(\"abcdef01-2345-6789-abcd-ef0123456789\"),\n",
    "            source=\"node_parsing\",\n",
    "            status=MessageSubProcessStatusEnum.FINISHED,\n",
    "            metadata_map=None\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "mock_document = Document(\n",
    "    id=UUID(\"123e4567-e89b-12d3-a456-426614174000\"),\n",
    "    created_at=datetime.now(),\n",
    "    updated_at=datetime.now(),\n",
    "    url=\"https://example.com/document.pdf\",\n",
    "    metadata_map={\n",
    "        DocumentMetadataKeysEnum.SEC_DOCUMENT: {\n",
    "            \"title\": \"Annual Report 2023\",\n",
    "            \"author\": \"Company XYZ\",\n",
    "            \"pages\": 25,\n",
    "            \"company_name\": \"Apple\",\n",
    "            \"company_ticker\": \"AAPL\",\n",
    "            \"doc_type\": SecDocumentTypeEnum.TEN_K,\n",
    "            \"year\": 2023\n",
    "            \n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "index.set_index_id(str(mock_document.id))\n",
    "doc_id_to_index = {\"123e4567-e89b-12d3-a456-426614174000\": index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e4b9e6f-8124-472c-b6b5-0c1e20a3f481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T19:50:04.948018Z",
     "iopub.status.busy": "2024-05-01T19:50:04.947722Z",
     "iopub.status.idle": "2024-05-01T19:50:04.978582Z",
     "shell.execute_reply": "2024-05-01T19:50:04.977754Z",
     "shell.execute_reply.started": "2024-05-01T19:50:04.947994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('123e4567-e89b-12d3-a456-426614174000')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_document.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e23c7f54-4b13-4723-9e01-2e0614bb5b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T19:50:06.899536Z",
     "iopub.status.busy": "2024-05-01T19:50:06.899195Z",
     "iopub.status.idle": "2024-05-01T19:50:06.931383Z",
     "shell.execute_reply": "2024-05-01T19:50:06.930551Z",
     "shell.execute_reply.started": "2024-05-01T19:50:06.899508Z"
    }
   },
   "outputs": [],
   "source": [
    "from app.schema import Conversation as ConversationSchema\n",
    "\n",
    "conversation = ConversationSchema(messages=[mock_message], documents=[mock_document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea5b339b-f661-4b57-be8b-a9825980c91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T19:50:07.336427Z",
     "iopub.status.busy": "2024-05-01T19:50:07.336123Z",
     "iopub.status.idle": "2024-05-01T19:50:07.368776Z",
     "shell.execute_reply": "2024-05-01T19:50:07.367949Z",
     "shell.execute_reply.started": "2024-05-01T19:50:07.336403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Apple (AAPL) 10-K (2023)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.chat.utils import build_title_for_document\n",
    "\n",
    "if conversation.documents:\n",
    "    doc_titles = \"\\n\".join(\n",
    "        \"- \" + build_title_for_document(doc) for doc in conversation.documents\n",
    "    )\n",
    "else:\n",
    "    doc_titles = \"No documents selected.\"\n",
    "\n",
    "doc_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae0e4f09-9d1d-4e18-b0f9-c981e204ed39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T19:50:09.389311Z",
     "iopub.status.busy": "2024-05-01T19:50:09.388976Z",
     "iopub.status.idle": "2024-05-01T19:50:09.418811Z",
     "shell.execute_reply": "2024-05-01T19:50:09.417826Z",
     "shell.execute_reply.started": "2024-05-01T19:50:09.389285Z"
    }
   },
   "outputs": [],
   "source": [
    "from app.chat.notebook_engine import get_chat_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ff0cf-d100-4044-885e-75cef0c04f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T03:04:56.791448Z",
     "iopub.status.busy": "2024-04-30T03:04:56.791042Z",
     "iopub.status.idle": "2024-04-30T03:04:56.834680Z",
     "shell.execute_reply": "2024-04-30T03:04:56.833301Z",
     "shell.execute_reply.started": "2024-04-30T03:04:56.791427Z"
    }
   },
   "source": [
    "[Llama Debug Handler](https://docs.llamaindex.ai/en/stable/examples/callbacks/LlamaDebugHandler/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52bf225d-3d72-4582-af30-ac6954d01269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T19:50:10.909721Z",
     "iopub.status.busy": "2024-05-01T19:50:10.909392Z",
     "iopub.status.idle": "2024-05-01T19:50:11.015233Z",
     "shell.execute_reply": "2024-05-01T19:50:11.014552Z",
     "shell.execute_reply.started": "2024-05-01T19:50:10.909695Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.callbacks import LlamaDebugHandler\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "\n",
    "agent = await get_chat_engine(conversation=conversation, doc_id_to_index=doc_id_to_index, callback_handler=llama_debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a79bec-96cb-491e-a18b-006e3cae4404",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38492043-b0b8-4824-a26a-6dc61b3449f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T19:50:12.133769Z",
     "iopub.status.busy": "2024-05-01T19:50:12.133392Z",
     "iopub.status.idle": "2024-05-01T19:50:13.402949Z",
     "shell.execute_reply": "2024-05-01T19:50:13.402134Z",
     "shell.execute_reply.started": "2024-05-01T19:50:12.133734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TURN 1\n",
      "---------------\n",
      "\n",
      "**********\n",
      "Trace: chat\n",
      "    |_CBEventType.AGENT_STEP ->  1.226806 seconds\n",
      "      |_CBEventType.LLM ->  1.226142 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# response = agent.chat(\"What did he work on outside of school?\")\n",
    "# response = agent.chat(\"What did he work on outside of school?\")\n",
    "response = agent.chat(\"What did the author do growing up?\")\n",
    "# TODO:\n",
    "# FIX FOR THIS MOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9cc36c2a-069a-4576-96a1-b7a1cbfcf484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T19:50:16.504971Z",
     "iopub.status.busy": "2024-05-01T19:50:16.504675Z",
     "iopub.status.idle": "2024-05-01T19:50:16.539972Z",
     "shell.execute_reply": "2024-05-01T19:50:16.538590Z",
     "shell.execute_reply.started": "2024-05-01T19:50:16.504948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"I'm sorry, but I don't have any information about the author's personal life or upbringing. My capabilities are limited to providing general information and answering questions based on the data I have been trained on. Is there anything else I can assist you with?\", sources=[], source_nodes=[])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6aef805a-b093-447d-8567-9fc658401a88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:48:30.996973Z",
     "iopub.status.busy": "2024-05-01T18:48:30.996678Z",
     "iopub.status.idle": "2024-05-01T18:48:31.030640Z",
     "shell.execute_reply": "2024-05-01T18:48:31.029567Z",
     "shell.execute_reply.started": "2024-05-01T18:48:30.996951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub Question 0: What is the employment history of the person?\n",
      "Answer: Empty Response\n",
      "====================================\n",
      "Sub Question 1: What is the author's name?\n",
      "Answer: Empty Response\n",
      "====================================\n",
      "Sub Question 2: What is the author's age?\n",
      "Answer: Empty Response\n",
      "====================================\n",
      "Sub Question 3: What is the author's educational background?\n",
      "Answer: Empty Response\n",
      "====================================\n",
      "Sub Question 4: What is the author's career history?\n",
      "Answer: Empty Response\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "# iterate through sub_question items captured in SUB_QUESTION event\n",
    "from llama_index.callbacks import CBEventType, EventPayload\n",
    "\n",
    "def print_subquestion_debug(llama_debug):\n",
    "    for i, (start_event, end_event) in enumerate(\n",
    "        llama_debug.get_event_pairs(CBEventType.SUB_QUESTION)\n",
    "    ):\n",
    "        qa_pair = end_event.payload[EventPayload.SUB_QUESTION]\n",
    "        print(\"Sub Question \" + str(i) + \": \" + qa_pair.sub_q.sub_question.strip())\n",
    "        print(\"Answer: \" + qa_pair.answer.strip())\n",
    "        print(\"====================================\")\n",
    "\n",
    "print_subquestion_debug(llama_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6733ef7-d5c2-4f1a-bad2-9ab5fead639f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:45:42.025384Z",
     "iopub.status.busy": "2024-05-01T18:45:42.024948Z",
     "iopub.status.idle": "2024-05-01T18:45:42.061097Z",
     "shell.execute_reply": "2024-05-01T18:45:42.060334Z",
     "shell.execute_reply.started": "2024-05-01T18:45:42.025359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"I'm sorry, but I don't have any information about what he worked on outside of school. Is there anything else I can help you with?\", sources=[ToolOutput(content='Empty Response', tool_name='qualitative_question_engine', raw_input={'input': 'What did he work on outside of school?'}, raw_output=Response(response='Empty Response', source_nodes=[NodeWithScore(node=TextNode(id_='53cc4700-713a-4742-919c-868b851b120c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7d5238a1bed65efaf5322516742e8a633b871cb5497a61c2d7ffff96f2b2374f', text='Sub question: What is the employment history of the person?\\nResponse: Empty Response', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None)], metadata={'53cc4700-713a-4742-919c-868b851b120c': {}}))], source_nodes=[NodeWithScore(node=TextNode(id_='53cc4700-713a-4742-919c-868b851b120c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7d5238a1bed65efaf5322516742e8a633b871cb5497a61c2d7ffff96f2b2374f', text='Sub question: What is the employment history of the person?\\nResponse: Empty Response', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None)])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77a22110-d1f6-436c-a879-1ba05aa2b167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:27:18.413218Z",
     "iopub.status.busy": "2024-05-01T17:27:18.412878Z",
     "iopub.status.idle": "2024-05-01T17:27:18.445762Z",
     "shell.execute_reply": "2024-05-01T17:27:18.445102Z",
     "shell.execute_reply.started": "2024-05-01T17:27:18.413195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EventStats(total_secs=1.101996, average_secs=1.101996, total_count=1)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.callbacks import CBEventType\n",
    "\n",
    "print(llama_debug.get_event_time_info(CBEventType.LLM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86dbde1d-7a7c-4c76-8237-7cfda2c8ab6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:29:51.517114Z",
     "iopub.status.busy": "2024-05-01T17:29:51.516820Z",
     "iopub.status.idle": "2024-05-01T17:29:51.552520Z",
     "shell.execute_reply": "2024-05-01T17:29:51.551806Z",
     "shell.execute_reply.started": "2024-05-01T17:29:51.517092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<EventPayload.MESSAGES: 'messages'>: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content=\"You are an expert financial analyst that always answers questions with the most relevant information using the tools at your disposal.\\nThese tools have information regarding companies that the user has expressed interest in.\\nHere are some guidelines that you must follow:\\n* For financial questions, you must use the tools to find the answer and then write a response.\\n* Even if it seems like your tools won't be able to answer the question, you must still use them to find the most relevant information and insights. Not using them will appear as if you are not doing your job.\\n* You may assume that the users financial questions are related to the documents they've selected.\\n* For any user message that isn't related to financial analysis, respectfully decline to respond and suggest that the user ask a relevant question.\\n* If your tools are unable to find an answer, you should say that you haven't found an answer but still relay any useful information the tools found.\\n\\nThe tools at your disposal have access to the following SEC documents that the user has selected to discuss with you:\\n- Apple (AAPL) 10-K (2023)\\n\\nThe current date is: 2024-05-01\", additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Hello, how can I help you?', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='What did he work on outside of school?', additional_kwargs={})],\n",
       " <EventPayload.ADDITIONAL_KWARGS: 'additional_kwargs'>: {'tools': [{'type': 'function',\n",
       "    'function': {'name': 'qualitative_question_engine',\n",
       "     'description': 'A query engine that can answer qualitative questions about a set of SEC financial documents that the user pre-selected for the conversation.\\nAny questions about company-related headwinds, tailwinds, risks, sentiments, or administrative information should be asked here.',\n",
       "     'parameters': {'title': 'DefaultToolFnSchema',\n",
       "      'description': 'Default tool function Schema.',\n",
       "      'type': 'object',\n",
       "      'properties': {'input': {'title': 'Input', 'type': 'string'}},\n",
       "      'required': ['input']}}}],\n",
       "  'tool_choice': 'auto'},\n",
       " <EventPayload.SERIALIZED: 'serialized'>: {'model': 'gpt-3.5-turbo-0613',\n",
       "  'temperature': 0.0,\n",
       "  'max_tokens': None,\n",
       "  'additional_kwargs': {},\n",
       "  'max_retries': 3,\n",
       "  'timeout': 60.0,\n",
       "  'default_headers': None,\n",
       "  'api_base': 'https://api.openai.com/v1',\n",
       "  'api_version': '',\n",
       "  'class_name': 'openai_llm'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print info on llm inputs/outputs - returns start/end events for each LLM call\n",
    "event_pairs = llama_debug.get_llm_inputs_outputs()\n",
    "event_pairs[0][0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b405129e-5fc8-4759-9783-2944d858ef8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:34:37.082990Z",
     "iopub.status.busy": "2024-05-01T17:34:37.082635Z",
     "iopub.status.idle": "2024-05-01T17:34:37.115687Z",
     "shell.execute_reply": "2024-05-01T17:34:37.115062Z",
     "shell.execute_reply.started": "2024-05-01T17:34:37.082962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([<EventPayload.MESSAGES: 'messages'>, <EventPayload.ADDITIONAL_KWARGS: 'additional_kwargs'>, <EventPayload.SERIALIZED: 'serialized'>])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_pairs[0][0].payload.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f95adab9-6724-4355-ae79-5f1c635beda0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:28:32.034035Z",
     "iopub.status.busy": "2024-05-01T17:28:32.033707Z",
     "iopub.status.idle": "2024-05-01T17:28:32.066311Z",
     "shell.execute_reply": "2024-05-01T17:28:32.065453Z",
     "shell.execute_reply.started": "2024-05-01T17:28:32.034012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([<EventPayload.MESSAGES: 'messages'>, <EventPayload.RESPONSE: 'response'>])\n"
     ]
    }
   ],
   "source": [
    "print(event_pairs[0][1].payload.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "215eb36e-6f9c-4d3f-95b7-e02553faee50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:28:37.648196Z",
     "iopub.status.busy": "2024-05-01T17:28:37.647845Z",
     "iopub.status.idle": "2024-05-01T17:28:37.680403Z",
     "shell.execute_reply": "2024-05-01T17:28:37.679650Z",
     "shell.execute_reply.started": "2024-05-01T17:28:37.648169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: I'm sorry, but I'm not sure who you are referring to. Could you please provide more context or clarify your question?\n"
     ]
    }
   ],
   "source": [
    "print(event_pairs[0][1].payload[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88801fbb-f3ae-4b1b-97e7-347f768c445f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:31:56.109512Z",
     "iopub.status.busy": "2024-05-01T17:31:56.109185Z",
     "iopub.status.idle": "2024-05-01T17:31:56.153378Z",
     "shell.execute_reply": "2024-05-01T17:31:56.152118Z",
     "shell.execute_reply.started": "2024-05-01T17:31:56.109487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert financial analyst that always answers questions with the most relevant information using the tools at your disposal.\n",
      "These tools have information regarding companies that the user has expressed interest in.\n",
      "Here are some guidelines that you must follow:\n",
      "* For financial questions, you must use the tools to find the answer and then write a response.\n",
      "* Even if it seems like your tools won't be able to answer the question, you must still use them to find the most relevant information and insights. Not using them will appear as if you are not doing your job.\n",
      "* You may assume that the users financial questions are related to the documents they've selected.\n",
      "* For any user message that isn't related to financial analysis, respectfully decline to respond and suggest that the user ask a relevant question.\n",
      "* If your tools are unable to find an answer, you should say that you haven't found an answer but still relay any useful information the tools found.\n",
      "\n",
      "The tools at your disposal have access to the following SEC documents that the user has selected to discuss with you:\n",
      "- Apple (AAPL) 10-K (2023)\n",
      "\n",
      "The current date is: 2024-05-01\n"
     ]
    }
   ],
   "source": [
    "# content for role=<MessageRole.SYSTEM: 'system'>\n",
    "print(\"You are an expert financial analyst that always answers questions with the most relevant information using the tools at your disposal.\\nThese tools have information regarding companies that the user has expressed interest in.\\nHere are some guidelines that you must follow:\\n* For financial questions, you must use the tools to find the answer and then write a response.\\n* Even if it seems like your tools won't be able to answer the question, you must still use them to find the most relevant information and insights. Not using them will appear as if you are not doing your job.\\n* You may assume that the users financial questions are related to the documents they've selected.\\n* For any user message that isn't related to financial analysis, respectfully decline to respond and suggest that the user ask a relevant question.\\n* If your tools are unable to find an answer, you should say that you haven't found an answer but still relay any useful information the tools found.\\n\\nThe tools at your disposal have access to the following SEC documents that the user has selected to discuss with you:\\n- Apple (AAPL) 10-K (2023)\\n\\nThe current date is: 2024-05-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b509587-3daf-4c64-9fdd-2dd82ce29389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Hello, how can I help you?', additional_kwargs={}),\n",
    "# ChatMessage(role=<MessageRole.USER: 'user'>, content='What did he work on outside of school?', additional_kwargs={})],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b39c8244-eeea-47ef-b6b0-dc1f6f5fdb77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:35:10.549688Z",
     "iopub.status.busy": "2024-05-01T17:35:10.549393Z",
     "iopub.status.idle": "2024-05-01T17:35:10.587055Z",
     "shell.execute_reply": "2024-05-01T17:35:10.586212Z",
     "shell.execute_reply.started": "2024-05-01T17:35:10.549663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBEvent(event_type=<CBEventType.LLM: 'llm'>, payload={<EventPayload.MESSAGES: 'messages'>: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content=\"You are an expert financial analyst that always answers questions with the most relevant information using the tools at your disposal.\\nThese tools have information regarding companies that the user has expressed interest in.\\nHere are some guidelines that you must follow:\\n* For financial questions, you must use the tools to find the answer and then write a response.\\n* Even if it seems like your tools won't be able to answer the question, you must still use them to find the most relevant information and insights. Not using them will appear as if you are not doing your job.\\n* You may assume that the users financial questions are related to the documents they've selected.\\n* For any user message that isn't related to financial analysis, respectfully decline to respond and suggest that the user ask a relevant question.\\n* If your tools are unable to find an answer, you should say that you haven't found an answer but still relay any useful information the tools found.\\n\\nThe tools at your disposal have access to the following SEC documents that the user has selected to discuss with you:\\n- Apple (AAPL) 10-K (2023)\\n\\nThe current date is: 2024-05-01\", additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Hello, how can I help you?', additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='What did he work on outside of school?', additional_kwargs={})], <EventPayload.ADDITIONAL_KWARGS: 'additional_kwargs'>: {'tools': [{'type': 'function', 'function': {'name': 'qualitative_question_engine', 'description': 'A query engine that can answer qualitative questions about a set of SEC financial documents that the user pre-selected for the conversation.\\nAny questions about company-related headwinds, tailwinds, risks, sentiments, or administrative information should be asked here.', 'parameters': {'title': 'DefaultToolFnSchema', 'description': 'Default tool function Schema.', 'type': 'object', 'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input']}}}], 'tool_choice': 'auto'}, <EventPayload.SERIALIZED: 'serialized'>: {'model': 'gpt-3.5-turbo-0613', 'temperature': 0.0, 'max_tokens': None, 'additional_kwargs': {}, 'max_retries': 3, 'timeout': 60.0, 'default_headers': None, 'api_base': 'https://api.openai.com/v1', 'api_version': '', 'class_name': 'openai_llm'}}, time='05/01/2024, 12:55:35.527080', id_='413544fa-29b5-4580-b082-33ee5702ed93')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_pairs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "416b210e-af69-461c-a0f4-412dba38f69e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:35:15.050693Z",
     "iopub.status.busy": "2024-05-01T17:35:15.050185Z",
     "iopub.status.idle": "2024-05-01T17:35:15.083775Z",
     "shell.execute_reply": "2024-05-01T17:35:15.083052Z",
     "shell.execute_reply.started": "2024-05-01T17:35:15.050669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBEvent(event_type=<CBEventType.LLM: 'llm'>, payload={<EventPayload.MESSAGES: 'messages'>: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content=\"You are an expert financial analyst that always answers questions with the most relevant information using the tools at your disposal.\\nThese tools have information regarding companies that the user has expressed interest in.\\nHere are some guidelines that you must follow:\\n* For financial questions, you must use the tools to find the answer and then write a response.\\n* Even if it seems like your tools won't be able to answer the question, you must still use them to find the most relevant information and insights. Not using them will appear as if you are not doing your job.\\n* You may assume that the users financial questions are related to the documents they've selected.\\n* For any user message that isn't related to financial analysis, respectfully decline to respond and suggest that the user ask a relevant question.\\n* If your tools are unable to find an answer, you should say that you haven't found an answer but still relay any useful information the tools found.\\n\\nThe tools at your disposal have access to the following SEC documents that the user has selected to discuss with you:\\n- Apple (AAPL) 10-K (2023)\\n\\nThe current date is: 2024-05-01\", additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Hello, how can I help you?', additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='What did he work on outside of school?', additional_kwargs={})], <EventPayload.RESPONSE: 'response'>: ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"I'm sorry, but I'm not sure who you are referring to. Could you please provide more context or clarify your question?\", additional_kwargs={}), raw={'id': 'chatcmpl-9K6auXG5Vvl0vJoV1Qd992ikwjvIc', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, but I'm not sure who you are referring to. Could you please provide more context or clarify your question?\", role='assistant', function_call=None, tool_calls=None))], 'created': 1714578936, 'model': 'gpt-3.5-turbo-0613', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=27, prompt_tokens=345, total_tokens=372)}, delta=None, additional_kwargs={})}, time='05/01/2024, 12:55:36.629076', id_='413544fa-29b5-4580-b082-33ee5702ed93')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_pairs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ea4ba98-ca88-434d-8ec7-9baf46412f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:49:38.966100Z",
     "iopub.status.busy": "2024-05-01T17:49:38.965806Z",
     "iopub.status.idle": "2024-05-01T17:49:39.000304Z",
     "shell.execute_reply": "2024-05-01T17:49:38.999075Z",
     "shell.execute_reply.started": "2024-05-01T17:49:38.966075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------- start_event ----------------\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content=\"You are an expert financial analyst that always answers questions with the most relevant information using the tools at your disposal.\\nThese tools have information regarding companies that the user has expressed interest in.\\nHere are some guidelines that you must follow:\\n* For financial questions, you must use the tools to find the answer and then write a response.\\n* Even if it seems like your tools won't be able to answer the question, you must still use them to find the most relevant information and insights. Not using them will appear as if you are not doing your job.\\n* You may assume that the users financial questions are related to the documents they've selected.\\n* For any user message that isn't related to financial analysis, respectfully decline to respond and suggest that the user ask a relevant question.\\n* If your tools are unable to find an answer, you should say that you haven't found an answer but still relay any useful information the tools found.\\n\\nThe tools at your disposal have access to the following SEC documents that the user has selected to discuss with you:\\n- Apple (AAPL) 10-K (2023)\\n\\nThe current date is: 2024-05-01\", additional_kwargs={}),\n",
      " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Hello, how can I help you?', additional_kwargs={}),\n",
      " ChatMessage(role=<MessageRole.USER: 'user'>, content='What did he work on outside of school?', additional_kwargs={})]\n",
      "\n",
      "\n",
      "---------------- end_event ----------------\n"
     ]
    }
   ],
   "source": [
    "from llama_index.callbacks import CBEventType, EventPayload\n",
    "import pprint\n",
    "\n",
    "for i, (start_event, end_event) in enumerate(\n",
    "    llama_debug.get_event_pairs(CBEventType.LLM)\n",
    "):\n",
    "    # qa_pair = end_event.payload[CBEventType.LLM]\n",
    "    print(\"\\n\\n---------------- start_event ----------------\")\n",
    "    pprint.pprint(start_event.payload[EventPayload.MESSAGES])\n",
    "    print(\"\\n\\n---------------- end_event ----------------\")\n",
    "    # print(end_event)\n",
    "    # print(\"Sub Question \" + str(i) + \": \" + qa_pair.sub_q.sub_question.strip())\n",
    "    # print(\"Answer: \" + qa_pair.answer.strip())\n",
    "    # print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c916ff-ca95-46f9-b91e-b3686620c913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
